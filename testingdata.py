# importing the csv files 
import pandas as pd

from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression
from sklearn.pipeline import make_pipeline
import numpy as np
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error 
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestClassifier

# trade from 449 after
def trade_simulation(predicted, actual, rf_preds, threshold, initial_cash):
    cash = initial_cash
    trades = 0
    
    # loop until n-1 index
    for i in range(len(actual) - 1):
        # Calculate predicted and actual gain
        predict_gain = ((predicted[i] - actual[i]) / actual[i]) * 100
        actual_gain = ((actual[i+1] - actual[i]) / actual[i]) * 100
        rf_vote = rf_preds[i]
        #predict_gain_dec
        
        #preduct_gain_lstm

        # Check if predicted gain mets the threshold
        if predict_gain >= threshold:
            if cash >= actual[i]: # if cash is enough
                # subtract its actual price. mimic buy stock
                cash -= actual[i]
                # sell the n+1 actual price. mimic sell stock
                cash += actual[i + 1]
                trades += 1
                print(f"Trade Success at {i+1}: Bought at {actual[i]:.2f} and sold at {actual[i+1]:.2f}, calculated gain {predict_gain:.2f}%, actual gains {actual_gain:.2f}%")
            else: # if you too poor :)
                print(f"Trade failed at {i+1}: Not enough cash to buy priced at {actual[i]:.2f} womp womp")
        else:
            print(f"Trade failed at {i+1}: Skipped (gain {predict_gain:.2f}% is less than the required {threshold}%)")
    
    return cash, trades

def regression_model(df_amazon, d):
    start_size = (len(df_amazon)) // 2

    predictions = []    
    actuals = [] 

    for i in range(start_size, len(df_amazon)):
        train_data = df_amazon.iloc[i - start_size:i]
        X_train = np.arange(start_size).reshape(-1, 1) 
        y_train = train_data['Open'].to_numpy()  
    
        # Use a degree 3 polynomial regression model.
        degree = d  
        model = make_pipeline(PolynomialFeatures(degree), LinearRegression())
        model.fit(X_train, y_train)
    
        # Predict the next value (the next apple's open price).
        next_index = np.array([[start_size]])  # the next index after the training window
        pred = model.predict(next_index)
    
        predictions.append(pred[0])
        actuals.append(df_amazon.iloc[i]['Open'])
    
    results = pd.DataFrame({
        'Actual_Open': actuals,
        'Predicted_Open': predictions
    }, index=df_amazon.index[start_size:])
    

    mse = mean_squared_error(actuals, predictions)
    mae = mean_absolute_error(actuals, predictions)
    r2 = r2_score(actuals, predictions)

    print("Mean Squared Error (MSE):", mse)
    print("Mean Absolute Error (MAE):", mae)
    print("RÂ² Score:", r2)
    print(results)
    return results  # Return the DataFrame with actual and predicted values.

def random_forest_model(df_amazon):
    split_index = len(df_amazon) // 2

    train_df = df_amazon.iloc[:split_index]
    test_df = df_amazon.iloc[split_index:].copy()

    features = ['Open', 'High', 'Low', 'Close', 'Volume', 'change_value']
    target = 'marginal_change'
    
    X_train = train_df[features]
    y_train = train_df[target]
    
    X_test = test_df[features]
    
    model = RandomForestClassifier(n_estimators=1000, random_state=42)
    model.fit(X_train, y_train)
    
    predictions = model.predict(X_test)
    probabilities = model.predict_proba(X_test)
    
    test_df['predicted'] = predictions
    # Column 1 is the probability that the price will increase.
    test_df['pct_increase'] = probabilities[:, 1] * 100
    test_df['pct_decrease'] = probabilities[:, 0] * 100
    print(test_df.head())
    return test_df

if __name__ == "__main__":
    # read csv
    df_amazon = pd.read_csv('amazon_data.csv')

    df_amazon = df_amazon.iloc[::-1]
    df_amazon = df_amazon.reset_index(drop=True)

    df_amazon['change_value']   = df_amazon['Open'].diff().fillna(0)
    df_amazon['marginal_change'] = (df_amazon['change_value'] > 0).astype(int)


    tester = [229, 229, 229.063720703125, 228.29513549804688, 228.1387939453125, 228.354736328125, 229.51785278320312, 228.52606201171875, 228.0560302734375, 226.4550018310547, 226.43161010742188, 226.7873992919922, 228.09422302246094, 229.0647430419922, 229.97604370117188, 230.6645050048828, 230.54515075683594, 231.3705291748047, 232.11741638183594, 232.2117462158203, 233.11643981933594, 231.76820373535156, 232.50616455078125, 232.33226013183594, 231.08108520507812, 230.7784423828125, 231.2000274658203, 230.92042541503906, 230.575439453125, 231.30613708496094, 231.67308044433594, 230.31201171875, 228.8941192626953, 229.59994506835938, 230.01815795898438, 229.15025329589844, 228.64610290527344, 228.04742431640625, 227.2053680419922, 225.0734405517578, 224.47669982910156, 224.44143676757812, 221.9661102294922, 222.08502197265625, 223.75869750976562, 225.31568908691406, 223.93605041503906, 223.8016357421875, 225.18191528320312, 225.36717224121094, 225.16543579101562, 226.01844787597656, 226.97470092773438, 226.1861114501953, 226.82374572753906, 226.25177001953125, 226.66909790039062, 226.6482391357422, 226.6340789794922, 225.96983337402344, 225.9866485595703, 226.64784240722656, 226.17547607421875, 225.88296508789062, 225.50401306152344, 225.26373291015625, 223.8424835205078, 222.3560333251953, 222.0937042236328, 222.62042236328125, 222.3582000732422, 221.18096923828125, 221.22308349609375, 221.66160583496094, 221.77099609375, 220.88726806640625, 220.4006805419922, 221.1902313232422, 220.90560913085938, 222.0580291748047, 222.6808319091797, 222.5049285888672, 221.6281280517578, 220.44871520996094, 219.9110870361328, 220.8765106201172, 222.4733123779297, 224.5118408203125, 224.50103759765625, 224.9735107421875, 222.18382263183594, 221.21990966796875, 220.86221313476562, 220.1171112060547, 221.119384765625, 223.15199279785156, 223.1948699951172, 223.72927856445312, 222.5229949951172, 222.4793701171875, 222.8475341796875, 222.7082977294922, 224.90684509277344, 226.44602966308594, 228.14724731445312, 228.18930053710938, 226.9637451171875, 226.2079620361328, 226.1577606201172, 227.09913635253906, 227.15914916992188, 226.45201110839844, 225.04420471191406, 223.59274291992188, 222.8434600830078, 222.7095947265625, 221.90248107910156, 222.73683166503906, 223.4052734375, 223.06068420410156, 222.5605926513672, 221.23873901367188, 221.2827606201172, 221.2166290283203, 221.91575622558594, 221.12533569335938, 221.2002716064453, 219.8051300048828, 219.26266479492188, 219.37393188476562, 219.39755249023438, 218.83311462402344, 218.86624145507812, 219.58343505859375, 219.40072631835938, 218.25347900390625, 217.8612060546875, 217.77703857421875, 218.018310546875, 217.78228759765625, 219.57388305664062, 220.7529754638672, 220.62847900390625, 219.43455505371094, 218.57431030273438, 218.73187255859375, 218.1123809814453, 217.44845581054688, 220.82864379882812, 222.9101104736328, 222.87425231933594, 222.5211944580078, 221.96583557128906, 221.8668975830078, 221.99046325683594, 221.74903869628906, 222.95655822753906, 223.83047485351562, 224.50718688964844, 223.3188934326172, 221.96554565429688, 220.96533203125, 221.3209991455078, 220.5060272216797, 223.6066436767578, 223.82186889648438, 224.60215759277344, 224.43264770507812, 223.89926147460938, 224.12054443359375, 224.99205017089844, 224.6851806640625, 227.88279724121094, 228.9960479736328, 229.9174041748047, 230.7622833251953, 230.2774658203125, 230.3705291748047, 231.6548309326172, 232.48379516601562, 234.19448852539062, 234.98464965820312, 235.11810302734375, 233.7720947265625, 233.1766357421875, 234.141357421875, 234.35939025878906, 234.22268676757812, 234.46568298339844, 235.20542907714844, 234.47137451171875, 233.0242156982422, 232.8489227294922, 233.51229858398438, 234.14620971679688, 235.43161010742188, 235.13636779785156, 234.50796508789062, 233.22177124023438, 233.16152954101562, 233.27737426757812, 233.5478973388672, 229.8931427001953, 232.42633056640625, 234.47299194335938, 234.46571350097656, 232.93690490722656, 233.93130493164062, 235.09100341796875, 236.12554931640625, 238.64227294921875, 241.8724365234375, 242.70663452148438, 242.946044921875, 242.3379364013672, 243.65467834472656, 242.4846649169922, 240.7339324951172, 240.46304321289062, 239.2555694580078, 237.30062866210938, 237.75848388671875, 239.19998168945312, 239.5206756591797, 239.88467407226562, 238.46029663085938, 237.7156219482422, 235.30111694335938, 235.21072387695312, 236.25323486328125, 237.21524047851562, 239.3970184326172, 240.4404754638672, 240.32371520996094, 239.10867309570312, 239.3916015625, 240.18402099609375, 239.11245727539062, 237.99221801757812, 239.83297729492188, 240.62240600585938, 240.4154052734375, 239.13485717773438, 238.7745361328125, 238.90721130371094, 239.4369354248047, 240.6044464111328, 241.54501342773438, 241.70582580566406, 240.56370544433594, 241.29722595214844, 242.52732849121094, 241.339599609375, 242.3332977294922, 241.94229125976562, 240.69517517089844, 238.90060424804688, 238.10496520996094, 238.77365112304688, 239.61074829101562, 240.0055389404297, 240.42636108398438, 239.22023010253906, 238.2164764404297, 239.34007263183594, 240.44454956054688, 240.32798767089844, 239.2041473388672, 240.74209594726562, 238.34164428710938, 235.51841735839844, 233.78321838378906, 232.7559356689453, 232.8233642578125, 232.62930297851562, 233.52223205566406, 234.23504638671875, 233.62933349609375, 231.92874145507812, 232.03289794921875, 232.65504455566406, 232.15750122070312, 233.15843200683594, 233.05661010742188, 232.23094177246094, 230.9119873046875, 231.0390167236328, 231.62025451660156, 230.9567108154297, 231.1606903076172, 231.54673767089844, 230.8992919921875, 229.49586486816406, 229.173095703125, 230.6207733154297, 229.9904327392578, 230.42547607421875, 231.53367614746094, 230.57183837890625, 228.79141235351562, 228.72557067871094, 230.52223205566406, 230.1583251953125, 230.67286682128906, 230.4373321533203, 229.82371520996094, 228.097412109375, 227.387451171875, 228.39649963378906, 228.9988555908203, 229.97857666015625, 230.18234252929688, 228.64549255371094, 227.10169982910156, 225.83314514160156, 225.95957946777344, 225.70132446289062, 226.57635498046875, 226.40013122558594, 226.10020446777344, 224.5738983154297, 224.34628295898438, 225.18153381347656, 224.9897003173828, 224.81480407714844, 224.99697875976562, 225.12579345703125, 224.1521759033203, 222.6757354736328, 221.78024291992188, 222.1221923828125, 222.8208465576172, 222.9069366455078, 222.7897491455078, 222.59994506835938, 220.579833984375, 218.98019409179688, 218.100830078125, 218.6754150390625, 217.2596893310547, 216.16419982910156, 215.90396118164062, 215.55812072753906, 214.93296813964844, 215.08786010742188, 214.25120544433594, 213.58424377441406, 213.89349365234375, 211.45016479492188, 210.102294921875, 209.15354919433594, 208.51849365234375, 210.54066467285156, 214.3233184814453, 217.18968200683594, 218.11988830566406, 217.98147583007812, 216.85433959960938, 215.89019775390625, 215.4509735107422, 217.8352508544922, 215.25172424316406, 215.76382446289062, 215.25692749023438, 214.72470092773438, 214.29469299316406, 213.89181518554688, 211.8759765625, 211.09619140625, 210.4231414794922, 210.93829345703125, 210.20404052734375, 209.18701171875, 208.5628662109375, 210.3831787109375, 212.87124633789062, 211.67999267578125, 210.97084045410156, 210.0272979736328, 209.99148559570312, 208.97842407226562, 208.7748565673828, 207.32516479492188, 203.596435546875, 202.3693389892578, 200.5282440185547, 201.41925048828125, 200.6648406982422, 201.54002380371094, 203.79208374023438, 204.38034057617188, 205.22647094726562, 206.4916534423828, 205.84466552734375, 207.47467041015625, 207.39002990722656, 208.4468994140625, 208.6012420654297, 206.75323486328125, 205.77264404296875, 205.5907745361328, 203.66429138183594, 202.8284454345703, 202.3483123779297, 201.66885375976562, 200.38975524902344, 199.43011474609375, 200.11033630371094, 198.8192596435547, 197.1190948486328, 195.9534912109375, 196.5836639404297, 196.21873474121094, 195.7239532470703, 197.3382110595703, 194.0917205810547, 192.98944091796875, 191.4849395751953, 190.366455078125, 191.9316864013672, 194.77125549316406, 197.40870666503906, 195.298828125, 194.77882385253906, 195.559326171875, 195.60250854492188, 197.62741088867188, 196.85986328125, 199.17971801757812, 199.25669860839844, 198.42530822753906, 198.61158752441406, 198.11129760742188, 196.8567657470703, 198.32273864746094, 198.7699432373047, 196.5358428955078, 196.37501525878906, 195.230712890625, 193.9227294921875, 192.3219757080078, 193.79010009765625, 193.0023956298828, 195.59808349609375, 195.96542358398438, 197.16064453125, 197.4493865966797, 197.5442657470703, 197.1775665283203]

    print(len(tester))
    # run the models
    degree = 5
    regression_data = regression_model(df_amazon, degree)
    # variables 
    # regression variable 

    predicted_prices = regression_data['Predicted_Open'].tolist()
    print(len(predicted_prices))
    actual_prices = regression_data['Actual_Open'].tolist()



    # decision tree variable   
    rf_results = random_forest_model(df_amazon)
    rf_preds = rf_results['predicted'].tolist()
    # lstm


    # init value
    threshold_percent = 2
    starting_cash = 1000

    # I can do a variable n-amount of stock buys based on the formula on kelly criterion
    # which requires decision tree to give information on what percentage picks bull market over bear
    # and picked side how much percentage on average ex. if 55% choose bull with 5% predicted gain 
    # and 45 bet lose  for 4% 

    # k% = (bp-q)b would be (.05*0.55-0.45)/0.05
    # i was wrong 
    # k = (bp-ql)/b would be (.05*0.55-0.45*0.04)/0.05 = 4.75  anything above a 1 means bet is favorable in one side
    # if negative then its not worth betting on

    # to-do with decision tree - make a 2d array [n][4] where it holds  n being the index
    # 1. percentage of population bet gain
    # 2. average of those percentage gains 
    # 3. percentage of population bet loss
    # 4. average of those percentage loss 

    # decision tree will only train on first half
    
    #final_cash, total_trades = trade_simulation(predicted_prices, actual_prices, rf_preds,threshold_percent, starting_cash)
    final_cash, total_trades = trade_simulation(tester, actual_prices, rf_preds,threshold_percent, starting_cash)
    print(f"Final cash in the basket: {final_cash:.2f}")
    print(f"Earned Amount: {final_cash-starting_cash:.2f}")
    print(f"Total trades made: {total_trades}")
    

